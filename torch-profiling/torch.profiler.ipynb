{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74321d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "model = nn.Sequential(nn.Linear(1000, 1000), nn.ReLU()).cuda()\n",
    "x = torch.randn(128, 1000).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18c73099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                        model_inference        37.71%       1.042ms        82.82%       2.288ms       2.288ms           0 B           0 B           0 B   -1001.00 KB             1  \n",
      "                                           aten::linear         0.38%      10.384us        39.55%       1.092ms       1.092ms           0 B           0 B     500.00 KB           0 B             1  \n",
      "                                                aten::t         1.15%      31.716us         2.19%      60.461us      15.115us           0 B           0 B           0 B           0 B             4  \n",
      "                                        aten::transpose         0.75%      20.628us         1.04%      28.745us       7.186us           0 B           0 B           0 B           0 B             4  \n",
      "                                       aten::as_strided         0.44%      12.122us         0.44%      12.122us       2.020us           0 B           0 B           0 B           0 B             6  \n",
      "                                            aten::addmm         3.96%     109.506us        37.80%       1.044ms       1.044ms           0 B           0 B     500.00 KB     500.00 KB             1  \n",
      "                                Activity Buffer Request        15.66%     432.601us        15.66%     432.601us     432.601us           0 B           0 B           0 B           0 B             1  \n",
      "                                        cudaMemsetAsync        17.12%     472.890us        17.12%     472.890us     472.890us           0 B           0 B           0 B           0 B             1  \n",
      "          cudaOccupancyMaxActiveBlocksPerMultiprocessor         0.25%       7.015us         0.25%       7.015us       3.508us           0 B           0 B           0 B           0 B             2  \n",
      "                                       cudaLaunchKernel         3.85%     106.447us         3.85%     106.447us      11.827us           0 B           0 B           0 B           0 B             9  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 2.762ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "with profile(\n",
    "    activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "    record_shapes=True,\n",
    "    profile_memory=True,          # 同时记录 CPU 和 GPU 内存（需 PyTorch ≥ 1.10）\n",
    "    with_stack=True,              # 记录调用栈（方便定位代码位置）\n",
    ") as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        output = model(x)\n",
    "        loss = output.sum()\n",
    "        loss.backward()\n",
    "\n",
    "# 打印表格\n",
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))\n",
    "\n",
    "# 保存为 TensorBoard 格式\n",
    "prof.export_chrome_trace(\"new_trace.json\")\n",
    "\n",
    "# 或直接启动 TensorBoard（需安装 tensorboard）\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "# writer = SummaryWriter()\n",
    "# writer.add_scalar(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f43c149",
   "metadata": {},
   "outputs": [],
   "source": [
    "with profile(\n",
    "    activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "    record_shapes=True,\n",
    "    profile_memory=True,          # 同时记录 CPU 和 GPU 内存（需 PyTorch ≥ 1.10）\n",
    "    with_stack=True,              # 记录调用栈（方便定位代码位置）) as prof:\n",
    "    # 预热（避免首次运行开销干扰）\n",
    ") as prof:\n",
    "    for _ in range(3):\n",
    "        _ = model(x)\n",
    "\n",
    "    # 正式 profiling\n",
    "    with record_function(\"main_run\"):\n",
    "        output = model(x)\n",
    "\n",
    "# 打印表格\n",
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
