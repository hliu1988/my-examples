{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b855ea7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                           aten::linear         0.06%      35.310us        62.37%      38.722ms      38.722ms      28.000us         0.05%      38.729ms      38.729ms             1  \n",
      "                                            aten::addmm        47.83%      29.695ms        62.22%      38.627ms      38.627ms      38.646ms        62.17%      38.646ms      38.646ms             1  \n",
      "                                              aten::sum         0.18%     109.999us        18.04%      11.201ms       3.734ms       5.647ms         9.08%      11.208ms       3.736ms             3  \n",
      "                                             aten::relu         0.09%      53.868us        17.58%      10.914ms      10.914ms      48.000us         0.08%      10.915ms      10.915ms             1  \n",
      "                                        aten::clamp_min         0.11%      65.839us        17.49%      10.855ms      10.855ms      10.867ms        17.48%      10.867ms      10.867ms             1  \n",
      "     autograd::engine::evaluate_function: ReluBackward0         0.02%      11.244us         6.27%       3.890ms       3.890ms      14.000us         0.02%       3.891ms       3.891ms             1  \n",
      "                                          ReluBackward0         0.03%      19.854us         6.24%       3.876ms       3.876ms      21.000us         0.03%       3.877ms       3.877ms             1  \n",
      "                               aten::threshold_backward         0.08%      52.077us         6.21%       3.852ms       3.852ms       3.856ms         6.20%       3.856ms       3.856ms             1  \n",
      "                                        aten::ones_like         0.03%      15.841us         3.57%       2.218ms       2.218ms      19.000us         0.03%       2.219ms       2.219ms             1  \n",
      "                                            aten::fill_         0.03%      21.261us         3.51%       2.181ms       2.181ms       2.183ms         3.51%       2.183ms       2.183ms             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 62.080ms\n",
      "Self CUDA time total: 62.159ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_424449/4087244249.py:7: FutureWarning: The attribute `use_cuda` will be deprecated soon, please use ``use_device = 'cuda'`` instead.\n",
      "  with torch.autograd.profiler.profile(use_cuda=True) as prof:\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "model = nn.Sequential(nn.Linear(1000, 1000), nn.ReLU()).cuda()\n",
    "x = torch.randn(128, 1000).cuda()\n",
    "\n",
    "with torch.autograd.profiler.profile(use_cuda=True) as prof:\n",
    "    output = model(x)\n",
    "    loss = output.sum()\n",
    "    loss.backward()\n",
    "\n",
    "# 打印分析结果（按 CUDA 时间排序）\n",
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01ec7d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_424449/2486754832.py:1: FutureWarning: The attribute `use_cuda` will be deprecated soon, please use ``use_device = 'cuda'`` instead.\n",
      "  with torch.autograd.profiler.profile(use_cuda=True) as prof:\n"
     ]
    }
   ],
   "source": [
    "with torch.autograd.profiler.profile(use_cuda=True) as prof:\n",
    "    output = model(x)\n",
    "\n",
    "# 保存为 JSON\n",
    "prof.export_chrome_trace(\"trace.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93f1e9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_424449/2853140831.py:1: FutureWarning: The attribute `use_cuda` will be deprecated soon, please use ``use_device = 'cuda'`` instead.\n",
      "  @torch.autograd.profiler.profile(use_cuda=True)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'profile' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;129;43m@torch\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprofiler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m(\u001b[49m\u001b[43muse_cuda\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43mrun_model\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m prof = run_model()\n",
      "\u001b[31mTypeError\u001b[39m: 'profile' object is not callable"
     ]
    }
   ],
   "source": [
    "@torch.autograd.profiler.profile(use_cuda=True)\n",
    "def run_model():\n",
    "    return model(x)\n",
    "\n",
    "prof = run_model()\n",
    "print(prof.key_averages().table())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
